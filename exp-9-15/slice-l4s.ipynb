{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script setup the experiments, assuming that the l4s part has been installed correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "tx0_prefix = \"ssh PeterYao@pc490.emulab.net\"\n",
    "router0_prefix = \"ssh PeterYao@pc500.emulab.net\"\n",
    "router1_prefix = \"ssh PeterYao@pc487.emulab.net\"\n",
    "rx0_prefix = \"ssh PeterYao@pc816.emulab.net\"\n",
    "\n",
    "nodes_prefix = [tx0_prefix, router0_prefix, router1_prefix, rx0_prefix]\n",
    "\n",
    "class node:\n",
    "    def __init__(self, node_ssh_prefix) -> None:\n",
    "        self.ssh_prefix = node_ssh_prefix\n",
    "\n",
    "    def execute(self, command, background=False):\n",
    "        if background:\n",
    "            print(\"executing in background\")\n",
    "            # full_command = f\"{self.ssh_prefix} 'setsid nohup {command} > /dev/null 2>&1 &'\"\n",
    "            full_command = f'{self.ssh_prefix} \"{command}\"'\n",
    "            subprocess.Popen(full_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        else:\n",
    "            full_command = f'{self.ssh_prefix} \"{command}\"'\n",
    "            result = subprocess.run(full_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            if result.returncode == 0:\n",
    "                print(result.stdout.decode('utf-8'))\n",
    "            else:\n",
    "                print(f\"Error: {result.stderr.decode('utf-8')}\")\n",
    "        return None\n",
    "        \n",
    "tx0_node = node(tx0_prefix)\n",
    "delay_node = node(router0_prefix)\n",
    "router_node = node(router1_prefix)\n",
    "rx0_node = node(rx0_prefix)\n",
    "\n",
    "nodes = [tx0_node, delay_node, router_node, rx0_node]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabric import Connection\n",
    "\n",
    "\n",
    "tx = Connection(\n",
    "    host='pc490.emulab.net',\n",
    "    user = 'PeterYao',\n",
    "    port=22,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "delay = Connection(\n",
    "    host='pc500.emulab.net',\n",
    "    user = 'PeterYao',\n",
    "    port=22,\n",
    ")\n",
    "\n",
    "\n",
    "router = Connection(\n",
    "    host='pc487.emulab.net',\n",
    "    user='PeterYao',\n",
    "    port=22,\n",
    ")\n",
    "\n",
    "rx = Connection(\n",
    "    host='pc816.emulab.net',\n",
    "    user\n",
    "    = 'PeterYao',  \n",
    "    port=22,\n",
    ")\n",
    "\n",
    "conns = [router, delay, tx, rx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3  add l4s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install the l4s kernel in each node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx.put(\"install_l4s_kernel.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rx.run(\" cp -r /mydata/core-network-5g/etc/ /local/repository/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rx.run(\"sudo ip route add 12.1.1.64/26 via 192.168.70.140\")\n",
    "rx.run(\"sudo ip route add 12.1.1.128/25 via 192.168.70.134\")\n",
    "\n",
    "rx.run(\"sudo iptables -P FORWARD ACCEPT \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the ue1 namespace:\n",
    "```\n",
    "sudo ip netns exec ue1 bash\n",
    "sudo ip route add default via 10.201.1.100\n",
    "```\n",
    "so that the icmp messages can be routed back to the sender. \n",
    "\n",
    "\n",
    "at the ue3 namesapce:\n",
    "```\n",
    "sudo ip netns exec ue3 bash\n",
    "sudo ip route add default via 10.203.1.100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay.put(\"install_l4s_kernel.sh\")\n",
    "# tx.put(\"install_l4s_kernel.sh\")\n",
    "# router.put(\"install_l4s_kernel.sh\")\n",
    "\n",
    "delay.run(\"chmod +x install_l4s_kernel.sh\")\n",
    "tx.run(\"chmod +x install_l4s_kernel.sh\")\n",
    "router.run(\"chmod +x install_l4s_kernel.sh\")\n",
    "\n",
    "delay.run(\"bash ./install_l4s_kernel.sh\", Warning=True)\n",
    "tx.run(\"bash ./install_l4s_kernel.sh\", Warning=True)\n",
    "router.run(\"bash ./install_l4s_kernel.sh\", Warning=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in conns:\n",
    "    c.run(\"uname -r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_dualpi2=\"\"\"sudo apt-get update\n",
    "sudo apt -y install git gcc make bison flex libdb-dev libelf-dev pkg-config libbpf-dev libmnl-dev libcap-dev libatm1-dev selinux-utils libselinux1-dev\n",
    "sudo git clone https://github.com/L4STeam/iproute2.git\n",
    "cd iproute2\n",
    "sudo chmod +x configure\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\"\"\"\n",
    "\n",
    "router.run(cmd_dualpi2)\n",
    "\n",
    "router.run(\"sudo modprobe sch_dualpi2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands_accecn='''\n",
    "sudo sysctl -w net.ipv4.tcp_congestion_control=prague  \n",
    "sudo sysctl -w net.ipv4.tcp_ecn=3''' \n",
    "\n",
    "rx.run(commands_accecn)\n",
    "tx.run(commands_accecn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# commands_noecn = \"bash -c 'sudo sysctl -w net.ipv4.tcp_congestion_control=cubic; sudo sysctl -w net.ipv4.tcp_ecn=0'\"\n",
    "# for node in nodes:\n",
    "#     node.execute(commands_noecn)\n",
    "    \n",
    "print(\"validating...\")\n",
    "for node in nodes:\n",
    "    node.execute(\"sudo sysctl net.ipv4.tcp_congestion_control\")\n",
    "    node.execute(\"sudo sysctl net.ipv4.tcp_ecn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, this cannot be automated\n",
    "\n",
    "for node in nodes:\n",
    "    # Download and unzip the kernel package\n",
    "    node.execute(\"wget https://github.com/L4STeam/linux/releases/download/testing-build/l4s-testing.zip\")\n",
    "    node.execute(\"sudo apt install unzip\")\n",
    "    node.execute(\"unzip l4s-testing.zip\")\n",
    "    \n",
    "    # Install the kernel packages and update GRUB\n",
    "    node.execute(\"sudo dpkg --install debian_build/*\")\n",
    "    node.execute(\"sudo update-grub\")\n",
    "    node.execute(\"sudo reboot\")\n",
    "\n",
    "for node in nodes:\n",
    "    # check kernel version\n",
    "    node.execute(\"hostname; uname -a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_dualpi2=\"\"\"sudo apt-get update\n",
    "sudo apt -y install git gcc make bison flex libdb-dev libelf-dev pkg-config libbpf-dev libmnl-dev libcap-dev libatm1-dev selinux-utils libselinux1-dev\n",
    "sudo git clone https://github.com/L4STeam/iproute2.git\n",
    "cd iproute2\n",
    "sudo chmod +x configure\n",
    "sudo ./configure\n",
    "sudo make\n",
    "sudo make install\"\"\"\n",
    "\n",
    "router.run(cmd_dualpi2)\n",
    "router.run(\"sudo modprobe sch_dualpi2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packages = ['iperf3', 'net-tools', 'moreutils']\n",
    "for conn in conns:\n",
    "    for package in packages:\n",
    "        conn.sudo(f'sudo apt update; apt-get -y install {package}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the delay on the delay node\n",
    "base_rtt = 25\n",
    "delay_interfaces = [\"enp5s0f0\", \"eno3\"]\n",
    "\n",
    "for e in delay_interfaces:\n",
    "    cmds = \"sudo tc qdisc replace dev {iface} root netem delay {owd}ms limit 60000\".format(iface=e, owd=base_rtt/2)\n",
    "    delay.run(cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay.run(\"sudo tc qdisc show dev enp5s0f0\")\n",
    "delay.run(\"sudo tc qdisc show dev eno3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the router queueing discipline\n",
    "router_egress_name = \"eno3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the btl node\n",
    "n_bdp = 2\n",
    "base_rtt = 25\n",
    "btl_capacity = 100 #in Mbps\n",
    "\n",
    "# fixed values\n",
    "btl_limit    = int(1000*n_bdp*btl_capacity*base_rtt/8) # limit of the bottleneck, n_bdp x BDP in bytes \n",
    "packet_number=int(btl_limit/1500)+1\n",
    "\n",
    "print(\"btl limit: \", btl_limit)\n",
    "print(\"packet number: \", packet_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cmds_prefix = '''\n",
    "            sudo tc qdisc del dev {iface} root\n",
    "            sudo tc qdisc replace dev {iface} root handle 1: htb default 3 \n",
    "            sudo tc class add dev {iface} parent 1: classid 1:3 htb rate {capacity}mbit \n",
    "            '''.format(iface=router_egress_name, capacity=btl_capacity, buffer=btl_limit)\n",
    "            \n",
    "cmds_specific = \"sudo tc qdisc add dev {iface} parent 1:3 handle 3: dualpi2 target {threshold}ms\".format(iface=router_egress_name, threshold=5)\n",
    "\n",
    "router.run(cmds_prefix)    \n",
    "router.run(cmds_specific)\n",
    "router.run(\"sudo tc qdisc show dev {iface}\".format(iface=router_egress_name))  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router.run(\"sudo tc qdisc show dev {iface}\".format(iface=router_egress_name))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in conns:\n",
    "    c.run(\"sudo sysctl -w net.ipv4.tcp_no_metrics_save=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in UE1 namespace\n",
    "```bash\n",
    "sudo sysctl -w  net.ipv4.tcp_congestion_control=prague\n",
    "sudo sysctl -w  net.ipv4.tcp_ecn=3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the iperf command\n",
    "\n",
    "rx.sudo(\"killall iperf3\", warn=True)\n",
    "\n",
    "# router_egress_name = \"eno3\"\n",
    "# router.run(\"sudo ethtool -S {iface}\".format(iface=router_egress_name))\n",
    "# router.run(\"ip -s link show {iface}\".format(iface=router_egress_name))\n",
    "\n",
    "rx.sudo(\"ip netns exec ue1 iperf3 -s -1 -p 4008 -D\")\n",
    "rx.sudo(\"ip netns exec ue3 iperf3 -s -1 -p 4008 -D\")\n",
    "\n",
    "local_file_path = r\"d:\\5g notes\\5G-E2E-Wireless-Notes-OAI\\exp-9-15\\exp.sh\"\n",
    "\n",
    "router.run(\"chmod +x ~/monitor_dual.sh\")\n",
    "\n",
    "# the monitor queue length shell script has already been copied to the router1 node\n",
    "router.run(\"nohup ./monitor.sh eno3 60 1 > monitor.log 2>&1 &\", pty=False)\n",
    "\n",
    "# the put command is funny on windows, so I copy paster the exp file manually to the tx node\n",
    "tx.run(\"chmod +x ~/exp.sh\")\n",
    "tx.run(\"~/exp.sh prague\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx.close()\n",
    "tx = Connection(\n",
    "    host='pc490.emulab.net',\n",
    "    user = 'PeterYao',\n",
    "    port=22,\n",
    ")\n",
    "tx.get(\"prague-result-ue1.json\")\n",
    "tx.get(\"prague-result-ue2.json\")\n",
    "tx.get(\"prague-ss-ue1.txt\")\n",
    "tx.get(\"prague-ss-ue2.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Replace these with the paths to your actual iperf JSON result files\n",
    "file1 = 'prague-result-ue1.json'\n",
    "file2 = 'prague-result-ue2.json'\n",
    "\n",
    "def load_iperf_data(filename):\n",
    "    \"\"\"Load iperf JSON data from a file and return a pandas DataFrame.\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Initialize lists to store the extracted data\n",
    "    intervals = data['intervals']\n",
    "    start_times = []\n",
    "    end_times = []\n",
    "    durations = []\n",
    "    throughputs = []\n",
    "    retransmissions = []\n",
    "    \n",
    "    # Iterate over each interval in the data\n",
    "    for interval in intervals:\n",
    "        sum_data = interval['sum']\n",
    "        start_times.append(sum_data['start'])\n",
    "        end_times.append(sum_data['end'])\n",
    "        durations.append(sum_data['seconds'])\n",
    "        # Convert throughput from bits per second to megabits per second\n",
    "        throughput_mbps = sum_data['bits_per_second'] / 1_000_000  # Divide by 1,000,000\n",
    "        throughputs.append(throughput_mbps)\n",
    "        retransmissions.append(sum_data.get('retransmits', 0))  # Retransmits might not be present in UDP tests\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Start Time': start_times,\n",
    "        'End Time': end_times,\n",
    "        'Duration': durations,\n",
    "        'Throughput (Mbps)': throughputs,\n",
    "        'Retransmissions': retransmissions\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filter_zero_throughput(df):\n",
    "    \"\"\"Filter out data points where throughput is zero.\"\"\"\n",
    "    return df[df['Throughput (Mbps)'] != 0].reset_index(drop=True)\n",
    "\n",
    "# Load data from both files\n",
    "df1 = load_iperf_data(file1)\n",
    "df2 = load_iperf_data(file2)\n",
    "\n",
    "# Filter out zero throughput data points for plotting throughput\n",
    "# df1_nonzero = filter_zero_throughput(df1)\n",
    "# df2_nonzero = filter_zero_throughput(df2)\n",
    "\n",
    "# Calculate overall throughput and average retransmissions for each dataset\n",
    "overall_throughput1 = df1['Throughput (Mbps)'].mean()\n",
    "average_retransmits1 = df1['Retransmissions'].mean()\n",
    "\n",
    "overall_throughput2 = df2['Throughput (Mbps)'].mean()\n",
    "average_retransmits2 = df2['Retransmissions'].mean()\n",
    "\n",
    "print(f\"UE 1 - Overall Throughput: {overall_throughput1:.2f} Mbps\")\n",
    "print(f\"UE 1 - Average Retransmissions: {average_retransmits1:.2f}\")\n",
    "\n",
    "print(f\"\\nUE 2 - Overall Throughput: {overall_throughput2:.2f} Mbps\")\n",
    "print(f\"UE 2 - Average Retransmissions: {average_retransmits2:.2f}\")\n",
    "\n",
    "# Plotting the throughputs over time (excluding zero throughput data points)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df1['Start Time'], df1['Throughput (Mbps)'], label='UE 1 Throughput', marker='o')\n",
    "plt.plot(df2['Start Time'], df2['Throughput (Mbps)'], label='UE 2 Throughput', marker='x')\n",
    "plt.title('Throughput Over Time (Excluding Zero Values)')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Throughput (Mbps)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plotting the retransmissions over time (include all data points)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df1['Start Time'], df1['Retransmissions'], label='UE 1 Retransmissions', marker='o')\n",
    "plt.plot(df2['Start Time'], df2['Retransmissions'], label='UE 2 Retransmissions', marker='x')\n",
    "plt.title('Retransmissions Over Time')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Number of Retransmissions')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMMENT: the cwnd calculation is not showing the expected result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "name_tx0=\"prague\"\n",
    "\n",
    "\n",
    "# the csv files generated is of the following format\n",
    "# timestamp, fd, cwnd, srtt\n",
    "\n",
    "file_out_tx0_csv = name_tx0+\"-ss.csv\"\n",
    "\n",
    "for ue_id in range(1, 3):\n",
    "    print(\"Running to generate csv files \" + name_tx0)\n",
    "\n",
    "    ss_tx0_script_processing=\"\"\"\n",
    "\n",
    "    f_1={types}; \n",
    "    ue_id={ue_id};\n",
    "    rm -f ${{f_1}}-ss-${{ue_id}}.csv;\n",
    "    cat ${{f_1}}-ss-${{ue_id}}.txt | sed -e \":a; /<->$/ {{ N; s/<->\\\\n//; ba; }}\"  | grep \"iperf3\" | grep -v \"SYN-SENT\"> ${{f_1}}-ss-processed-${{ue_id}}.txt; \n",
    "    cat ${{f_1}}-ss-processed-${{ue_id}}.txt | awk '{{print $1}}' > ts-${{f_1}}-${{ue_id}}.txt; \n",
    "    cat ${{f_1}}-ss-processed-${{ue_id}}.txt | grep -oP '\\\\bcwnd:.*?(\\s|$)' | awk -F '[:,]' '{{print $2}}' | tr -d ' ' > cwnd-${{f_1}}-${{ue_id}}.txt; \n",
    "    cat ${{f_1}}-ss-processed-${{ue_id}}.txt | grep -oP '\\\\brtt:.*?(\\s|$)' | awk -F '[:,]' '{{print $2}}' | tr -d ' '  | cut -d '/' -f 1   > srtt-${{f_1}}-${{ue_id}}.txt; \n",
    "    cat ${{f_1}}-ss-processed-${{ue_id}}.txt | grep -oP '\\\\bfd=.*?(\\s|$)' | awk -F '[=,]' '{{print $2}}' | tr -d ')' | tr -d ' '   > fd-${{f_1}}-${{ue_id}}.txt;\n",
    "    paste ts-${{f_1}}-${{ue_id}}.txt fd-${{f_1}}-${{ue_id}}.txt cwnd-${{f_1}}-${{ue_id}}.txt srtt-${{f_1}}-${{ue_id}}.txt -d ',' > ${{f_1}}-ss-${{ue_id}}.csv;\"\"\".format(types=name_tx0, ue_id=\"ue\"+str(ue_id))\n",
    "\n",
    "    tx.run(ss_tx0_script_processing)\n",
    "\n",
    "tx.get(\"prague\"+\"-ss-ue1.csv\")\n",
    "tx.get(\"prague\"+\"-ss-ue2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "throughput_data = {}  # Initialize the dictionary\n",
    "srtt_data = {}\n",
    "cwnd_data= pd.DataFrame()\n",
    "srtt_data_time= pd.DataFrame()\n",
    "\n",
    "for ue_id in range(1, 3):\n",
    "    name_tx0=\"prague\"\n",
    "    ue_str = \"ue\"+str(ue_id)\n",
    "\n",
    "    # Load the JSON output file into a Python object\n",
    "    with open(f\"{name_tx0}-result-{ue_str}.json\") as f:\n",
    "        iperf3_data = json.load(f)\n",
    "\n",
    "    throughput_data[name_tx0+ue_str] = iperf3_data['end']['sum_received']['bits_per_second'] / (1000000 * 1)  # to convert Mbit\n",
    "\n",
    "    # Average SRTT for Each Flow\n",
    "    columns = ['timestamp', 'flow ID', 'cwnd', 'srtt']\n",
    "    df_f1 = pd.read_csv(f\"{name_tx0}-ss-{ue_str}.csv\", names=columns)\n",
    "    \n",
    "    # Filter out rows with flow ID = 4, they are for the control flows\n",
    "    df_f1 = df_f1[df_f1['flow ID'] != 4].reset_index(drop=True)\n",
    "\n",
    "    average_RTT_f1 = df_f1['srtt'].mean()\n",
    "    \n",
    "    cwnd_data[name_tx0+ue_str] = df_f1['cwnd']\n",
    "    srtt_data[name_tx0+ue_str] = average_RTT_f1\n",
    "    srtt_data_time[name_tx0+ue_str] = df_f1['srtt']\n",
    "\n",
    "# Save throughput_data to a JSON file\n",
    "with open('throughput_data.json', 'w') as f:\n",
    "    json.dump(throughput_data, f)\n",
    "\n",
    "# Save srtt_data to a JSON file\n",
    "with open('srtt_data.json', 'w') as f:\n",
    "    json.dump(srtt_data, f)\n",
    "\n",
    "cwnd_data.to_csv(\"consolidated_cwnd_data.csv\", index=False)\n",
    "srtt_data_time.to_csv(\"time_srtt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "btl_limit_noecn=int(1000*btl_capacity*base_rtt*n_bdp /8)\n",
    "\n",
    "print(\"btl limit no ecn: \", btl_limit_noecn)\n",
    "\n",
    "# Specify the filename\n",
    "filename = 'consolidated_cwnd_data.csv'  # Replace with your actual filename\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Extract data for each UE\n",
    "ue1_data = df['pragueue1']\n",
    "ue2_data = df['pragueue2']\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 6))\n",
    "\n",
    "# Plot for UE1\n",
    "axes[0].plot(ue1_data*1448, marker='', color='blue')\n",
    "axes[0].set_title('Congestion Window (cwnd) Over Time - UE1')\n",
    "axes[0].set_xlabel('Time Interval')\n",
    "axes[0].set_ylabel('cwnd (segments)')\n",
    "axes[0].axhline(y=btl_limit_noecn, color='b', linestyle='--', label=f'Buffer Size')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot for UE2\n",
    "axes[1].plot(ue2_data*1448, marker='', color='orange')\n",
    "axes[1].set_title('Congestion Window (cwnd) Over Time - UE2')\n",
    "axes[1].set_xlabel('Time Interval')\n",
    "axes[1].set_ylabel('cwnd (segments)')\n",
    "axes[1].axhline(y=btl_limit_noecn, color='b', linestyle='--', label=f'Buffer Size')\n",
    "axes[1].grid(True)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plots\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "router.close()\n",
    "router = Connection(\n",
    "    host='pc487.emulab.net',\n",
    "    user='PeterYao',\n",
    "    port=22,\n",
    ")\n",
    "\n",
    "router.get(\"monitor.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define a function to parse the log file\n",
    "def parse_qdisc_log(filename):\n",
    "    timestamps = []\n",
    "    packet_drops = []\n",
    "    queue_lengths = []\n",
    "    ecn_marks = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Extract timestamp\n",
    "            match_time = re.match(r'^(\\d+\\.\\d+)', line)\n",
    "            if match_time:\n",
    "                timestamps.append(float(match_time.group(1)))\n",
    "\n",
    "            # Extract packet drops, queue length, and ECN mark count for dualpi2 queue\n",
    "            match_dualpi2 = re.search(r'qdisc dualpi2.*dropped (\\d+).*backlog (\\d+)b.*ecn_mark (\\d+)', line)\n",
    "            if match_dualpi2:\n",
    "                packet_drops.append(int(match_dualpi2.group(1)))\n",
    "                queue_lengths.append(int(match_dualpi2.group(2)))\n",
    "                ecn_marks.append(int(match_dualpi2.group(3)))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Timestamp': timestamps[:len(packet_drops)],  # Align timestamps with the collected data\n",
    "        'Packet Drops': packet_drops,\n",
    "        'Queue Length (bytes)': queue_lengths,\n",
    "        'ECN Marks': ecn_marks\n",
    "    })\n",
    "    \n",
    "    # Normalize timestamps to start from 0\n",
    "    df['Relative Time (s)'] = df['Timestamp'] - df['Timestamp'].iloc[0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Step 2: Define a function to plot packet drops, queue length, and ECN mark count\n",
    "def plot_qdisc_metrics(df):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot packet drops\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(df['Relative Time (s)'], df['Packet Drops'], label=\"Packet Drops\", color='r', marker='o')\n",
    "    plt.title('Packet Drops Over Time')\n",
    "    plt.ylabel('Packet Drops')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot queue length\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(df['Relative Time (s)'], df['Queue Length (bytes)'], label=\"Queue Length\", color='b', marker='o')\n",
    "    plt.title('Queue Length Over Time')\n",
    "    plt.ylabel('Queue Length (bytes)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot ECN marks\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(df['Relative Time (s)'], df['ECN Marks'], label=\"ECN Marks\", color='g', marker='o')\n",
    "    plt.title('ECN Marks Over Time')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('ECN Marks')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Read the file and generate plots\n",
    "filename = 'monitor.log'  # Update the file path as needed\n",
    "df = parse_qdisc_log(filename)\n",
    "plot_qdisc_metrics(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Define a function to parse the log file\n",
    "def parse_qdisc_log(filename):\n",
    "    timestamps = []\n",
    "    packet_drops = []\n",
    "    queue_lengths = []\n",
    "    ecn_marks = []\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "\n",
    "            # Extract timestamp\n",
    "            match_time = re.match(r'^(\\d+\\.\\d+)', line)\n",
    "            if match_time:\n",
    "                timestamps.append(float(match_time.group(1)))\n",
    "\n",
    "            # Extract packet drops, queue length, and ECN mark count for dualpi2 queue\n",
    "            match_dualpi2 = re.search(r'qdisc dualpi2.*dropped (\\d+).*backlog (\\d+)b.*ecn_mark (\\d+)', line)\n",
    "            if match_dualpi2:\n",
    "                packet_drops.append(int(match_dualpi2.group(1)))\n",
    "                queue_lengths.append(int(match_dualpi2.group(2)))\n",
    "                ecn_marks.append(int(match_dualpi2.group(3)))\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Timestamp': timestamps[:len(packet_drops)],  # Align timestamps with the collected data\n",
    "        'Packet Drops': packet_drops,\n",
    "        'Queue Length (bytes)': queue_lengths,\n",
    "        'ECN Marks': ecn_marks\n",
    "    })\n",
    "    \n",
    "    # Normalize timestamps to start from 0\n",
    "    df['Relative Time (s)'] = df['Timestamp'] - df['Timestamp'].iloc[0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Step 2: Define a function to plot packet drops, queue length, and ECN mark count\n",
    "def plot_qdisc_metrics(df):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot packet drops\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.plot(df['Relative Time (s)'], df['Packet Drops'], label=\"Packet Drops\", color='r', marker='o')\n",
    "    plt.title('Packet Drops Over Time')\n",
    "    plt.ylabel('Packet Drops')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot queue length\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(df['Relative Time (s)'], df['Queue Length (bytes)'], label=\"Queue Length\", color='b', marker='o')\n",
    "    plt.title('Queue Length Over Time')\n",
    "    plt.ylabel('Queue Length (bytes)')\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot ECN marks\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(df['Relative Time (s)'], df['ECN Marks'], label=\"ECN Marks\", color='g', marker='o')\n",
    "    plt.title('ECN Marks Over Time')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('ECN Marks')\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Read the file and generate plots\n",
    "filename = 'monitor.log'  # Replace this with the actual path to your file\n",
    "df = parse_qdisc_log(filename)\n",
    "plot_qdisc_metrics(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path to the uploaded CSV file\n",
    "file_path = 'time_srtt.csv'\n",
    "\n",
    "# Reading the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calculate the average SRTT for each UE\n",
    "avg_ue1 = df['pragueue1'].mean()\n",
    "avg_ue2 = df['pragueue2'].mean()\n",
    "\n",
    "# Plot the SRTT changes over time for both UE1 and UE2\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df.index, df['pragueue1'], label='pragueue1', marker='o')\n",
    "plt.plot(df.index, df['pragueue2'], label='pragueue2', marker='s')\n",
    "\n",
    "# Plot average lines\n",
    "plt.axhline(y=avg_ue1, color='blue', linestyle='--', linewidth=1, label=f'Average UE1 ({avg_ue1:.2f} ms)')\n",
    "plt.axhline(y=avg_ue2, color='green', linestyle='--', linewidth=1, label=f'Average UE2 ({avg_ue2:.2f} ms)')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Time (Index)')\n",
    "plt.ylabel('SRTT (ms)')\n",
    "plt.title('SRTT Changes Over Time for cubic_ecn_noneue1 and cubic_ecn_noneue2')\n",
    "\n",
    "# Adding a legend and grid\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the average SRTT for each UE\n",
    "print(f\"Average SRTT for cubic_ecn_noneue1: {avg_ue1:.3f} ms\")\n",
    "print(f\"Average SRTT for cubic_ecn_noneue2: {avg_ue2:.3f} ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
